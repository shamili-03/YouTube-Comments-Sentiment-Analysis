# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NOsq0Yo-5CPyjc3OpkR8UJPPhW9IcaMW
"""

pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client pandas transformers torch

import os
import pandas as pd
from googleapiclient.discovery import build
from transformers import pipeline

# Set up the YouTube API key
api_key = "AIzaSyA_DzT7DdZd_j81Vb3BNt8y6ngyti1LTtM"  # Replace with your YouTube API Key
youtube = build('youtube', 'v3', developerKey=api_key)

# Function to scrape YouTube comments
def get_comments(video_id):
    comments = []
    request = youtube.commentThreads().list(
        part="snippet",
        videoId=video_id,
        maxResults=100
    )
    response = request.execute()

    while response:
        for item in response['items']:
            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
            comments.append(comment)

        if 'nextPageToken' in response:
            request = youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                pageToken=response['nextPageToken'],
                maxResults=100
            )
            response = request.execute()
        else:
            break

    return comments

# Function to save comments to a CSV file
def save_comments_to_csv(comments, video_id):
    df = pd.DataFrame(comments, columns=['Comment'])
    file_name = f'{video_id}_comments.csv'
    df.to_csv(file_name, index=False)
    print(f"Comments saved to {file_name}")
    return file_name

# Function to perform sentiment analysis on the comments with truncation
def analyze_sentiments(comments, max_length=512):
    classifier = pipeline('sentiment-analysis')
    sentiments = []

    for comment in comments:
        truncated_comment = comment[:max_length]
        sentiment = classifier(truncated_comment)[0]
        sentiments.append({
            'Comment': truncated_comment,
            'Sentiment': sentiment['label'],
            'Score': sentiment['score']
        })

    return sentiments

# Function to save sentiments to a CSV file
def save_sentiments_to_csv(sentiments, video_id):
    df = pd.DataFrame(sentiments)
    file_name = f'{video_id}_sentiments.csv'
    df.to_csv(file_name, index=False)
    print(f"Sentiments saved to {file_name}")

# Main function to scrape comments, analyze sentiment, and save results
def main():
    # Get the YouTube video link from the user
    video_link = input("Paste the YouTube video link: ")
    video_id = video_link.split('v=')[-1]  # Extract the video ID from the link

    # Scrape comments
    comments = get_comments(video_id)

    # Save comments to a CSV file
    save_comments_to_csv(comments, video_id)

    # Analyze sentiment with truncation
    sentiments = analyze_sentiments(comments)

    # Save sentiments to a CSV file
    save_sentiments_to_csv(sentiments, video_id)

if __name__ == "__main__":
    main()